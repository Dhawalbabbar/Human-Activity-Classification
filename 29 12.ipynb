{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_X(X_signals_paths):\n",
    "    X_signals = []\n",
    "\n",
    "    for signal_type_path in X_signals_paths:\n",
    "        file = open(signal_type_path, 'r')\n",
    "        # Read dataset from disk, dealing with text files' syntax\n",
    "        X_signals.append(\n",
    "            [np.array(serie, dtype=np.float32) for serie in [\n",
    "                row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "            ]]\n",
    "        )\n",
    "        file.close()\n",
    "\n",
    "    return np.transpose(np.array(X_signals), (1, 2, 0))\n",
    "\n",
    "\n",
    "# Load \"y\" (the neural network's training and testing outputs)\n",
    "\n",
    "def load_y(y_path):\n",
    "    file = open(y_path, 'r')\n",
    "    # Read dataset from disk, dealing with text file's syntax\n",
    "    y_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "        ]],\n",
    "        dtype=np.int32\n",
    "    )\n",
    "    file.close()\n",
    "    # Substract 1 to each output class for friendly 0-based indexing\n",
    "    return y_ - 1\n",
    "\n",
    "def one_hot(y_):\n",
    "    \"\"\"\n",
    "    Function to encode output labels from number indexes.\n",
    "    E.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
    "    \"\"\"\n",
    "    y_ = y_.reshape(len(y_))\n",
    "    n_values = int(np.max(y_)) + 1\n",
    "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    \"\"\"\n",
    "    define a class to store parameters,\n",
    "    the input should be feature mat of training and testing\n",
    "    Note: it would be more interesting to use a HyperOpt search space:\n",
    "    https://github.com/hyperopt/hyperopt\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_train, X_test):\n",
    "        # Input data\n",
    "        self.train_count = len(X_train)  # 7352 training series\n",
    "        self.test_data_count = len(X_test)  # 2947 testing series\n",
    "        self.n_steps = len(X_train[0])  # 128 time_steps per series\n",
    "\n",
    "        # Training\n",
    "        self.learning_rate = 0.0025\n",
    "        self.lambda_loss_amount = 0.0015\n",
    "        self.training_epochs = 300\n",
    "        self.batch_size = 1500\n",
    "\n",
    "        # LSTM structure\n",
    "        self.n_inputs = len(X_train[0][0])  # Features count is of 9: 3 * 3D sensors features over time\n",
    "        self.n_hidden = 32  # nb of neurons inside the neural network\n",
    "        self.n_classes = 6  # Final output classes\n",
    "        self.W = {\n",
    "            'hidden': tf.Variable(tf.random_normal([self.n_inputs, self.n_hidden])),\n",
    "            'output': tf.Variable(tf.random_normal([self.n_hidden, self.n_classes]))\n",
    "        }\n",
    "        self.biases = {\n",
    "            'hidden': tf.Variable(tf.random_normal([self.n_hidden], mean=1.0)),\n",
    "            'output': tf.Variable(tf.random_normal([self.n_classes]))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Network(_X, config):\n",
    "    \"\"\"Function returns a TensorFlow RNN with two stacked LSTM cells\n",
    "    Two LSTM cells are stacked which adds deepness to the neural network.\n",
    "    Note, some code of this notebook is inspired from an slightly different\n",
    "    RNN architecture used on another dataset, some of the credits goes to\n",
    "    \"aymericdamien\".\n",
    "    Args:\n",
    "        _X:     ndarray feature matrix, shape: [batch_size, time_steps, n_inputs]\n",
    "        config: Config for the neural network.\n",
    "    Returns:\n",
    "        This is a description of what is returned.\n",
    "    Raises:\n",
    "        KeyError: Raises an exception.\n",
    "      Args:\n",
    "        feature_mat: ndarray fature matrix, shape=[batch_size,time_steps,n_inputs]\n",
    "        config: class containing config of network\n",
    "      return:\n",
    "              : matrix  output shape [batch_size,n_classes]\n",
    "    \"\"\"\n",
    "    # (NOTE: This step could be greatly optimised by shaping the dataset once\n",
    "    # input shape: (batch_size, n_steps, n_input)\n",
    "    _X = tf.transpose(_X, [1, 0, 2])  # permute n_steps and batch_size\n",
    "    # Reshape to prepare input to hidden activation\n",
    "    _X = tf.reshape(_X, [-1, config.n_inputs])\n",
    "    # new shape: (n_steps*batch_size, n_input)\n",
    "\n",
    "    # Linear activation\n",
    "    _X = tf.nn.relu(tf.matmul(_X, config.W['hidden']) + config.biases['hidden'])\n",
    "    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "    _X = tf.split(_X, config.n_steps, 0)\n",
    "    # new shape: n_steps * (batch_size, n_hidden)\n",
    "\n",
    "    # Define two stacked LSTM cells (two recurrent layers deep) with tensorflow\n",
    "    lstm_cell_1 = tf.contrib.rnn.BasicLSTMCell(config.n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "    lstm_cell_2 = tf.contrib.rnn.BasicLSTMCell(config.n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "    lstm_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell_1, lstm_cell_2], state_is_tuple=True)\n",
    "    # Get LSTM cell output\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(lstm_cells, _X, dtype=tf.float32)\n",
    "\n",
    "    # Get last time step's output feature for a \"many to one\" style classifier,\n",
    "    # as in the image describing RNNs at the top of this page\n",
    "    lstm_last_output = outputs[-1]\n",
    "\n",
    "    # Linear activation\n",
    "    return tf.matmul(lstm_last_output, config.W['output']) + config.biases['output']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset is now located at: UCI HAR Dataset/\n",
      "(7352, 25, 6)\n",
      "(875, 6)\n",
      "[-0.3909215   0.6437743  -0.03510151  0.04559934  0.6319096  -0.2857544 ]\n",
      "[[  1.17733300e-01   2.77377800e-02   3.00868200e-02  -7.39096000e-03\n",
      "   -1.23147600e-02   2.40465000e-02]\n",
      " [  3.56921100e-01  -6.53331100e-02   1.81200600e-01  -8.18812800e-02\n",
      "    9.28386700e-02   5.23578000e-02]\n",
      " [  9.73180000e-01   3.58738500e-01  -2.96835000e-02  -2.20969500e-01\n",
      "    6.52620200e-01   3.86742000e-02]\n",
      " [  5.44997900e-01  -2.01110300e-03  -3.89643300e-04  -2.27229900e-01\n",
      "    1.45090200e+00  -1.89259800e-02]\n",
      " [ -1.66387500e-01  -2.52928000e-01   1.97789000e-01  -1.63690800e-01\n",
      "    1.75868300e+00   7.38319000e-02]\n",
      " [ -7.72060000e-01   8.58477500e-02  -2.29707400e-01  -1.23769800e-01\n",
      "    1.04568600e+00   1.10587000e-01]\n",
      " [  1.34241700e-01   5.72452400e-02   1.79506200e-01  -1.98581600e-02\n",
      "    6.02074800e-01   1.38996300e-01]\n",
      " [  2.11206600e-01   4.53148800e-01   4.08803000e-01  -7.79590600e-03\n",
      "    8.50906400e-01   1.04419200e-01]\n",
      " [  7.00913500e-01  -2.71800300e-01   6.77213600e-01  -4.30516100e-03\n",
      "    1.54988100e+00   7.38037000e-02]\n",
      " [ -4.12979700e-01  -4.39817500e-01   1.23189500e-01   5.17826700e-02\n",
      "    2.33994600e+00   8.52841300e-02]\n",
      " [ -4.54710400e-01   3.11303500e-01   6.23965100e-01   3.34905900e-02\n",
      "    2.24382600e+00   3.01850900e-01]\n",
      " [ -5.66441500e-01  -5.87240800e-01  -6.14403100e-01   1.91240000e-01\n",
      "    2.06544300e+00   8.54758800e-02]\n",
      " [ -1.69548800e-01   5.11640300e-03  -8.73748700e-01   5.18955500e-01\n",
      "    1.13324100e+00   4.03548600e-02]\n",
      " [ -3.25087800e-01   5.76238400e-01  -9.77991500e-01   3.51930800e-01\n",
      "    2.16030800e-01   3.46279300e-02]\n",
      " [ -7.75404100e-02  -3.04858500e-01   6.59607600e-01   5.24005800e-01\n",
      "   -9.95873500e-02  -2.33332200e-01]\n",
      " [ -1.19728600e-01   1.65514500e-01   1.94003900e-01   4.74471800e-01\n",
      "    1.48038200e-01  -1.88190200e-01]\n",
      " [ -2.97761900e-01   5.79498200e-01   4.78139000e-01   1.88573800e-01\n",
      "    2.90792900e-01   5.43347200e-02]\n",
      " [ -1.09004900e-01   3.96362800e-01   1.41459600e+00   9.10630300e-03\n",
      "    7.86267600e-01   1.80405600e-01]\n",
      " [ -9.69915400e-02  -7.51798400e-01  -6.87227400e-01   3.32421800e-02\n",
      "    1.66344000e+00   1.81405000e-01]\n",
      " [ -1.12591100e-01  -8.46249300e-02  -9.32497600e-01   2.15726900e-01\n",
      "    8.10598200e-01   1.05050800e-01]\n",
      " [ -2.21285600e-01   7.27170000e-02  -6.24988700e-01  -3.23714400e-03\n",
      "    5.37044700e-01  -1.13859300e-01]\n",
      " [  5.30084400e-02   1.95457000e-01   2.23524400e-01  -2.66831500e-01\n",
      "    4.61133600e-01  -8.37185700e-02]\n",
      " [ -3.02018100e-01   9.37898700e-02  -5.96001700e-01   2.25931500e-01\n",
      "    1.36467300e+00  -3.52133100e-01]\n",
      " [  1.82695500e-01  -2.25998000e-01  -7.28761900e-01   1.06058300e-01\n",
      "    6.87116100e-01  -4.06395400e-01]\n",
      " [ -3.90921500e-01   6.43774300e-01  -3.51015100e-02   4.55993400e-02\n",
      "    6.31909600e-01  -2.85754400e-01]]\n",
      "(35, 25, 6)\n",
      "[[ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]]\n",
      "Some useful info to get an insight on dataset's shape and normalisation:\n",
      "features shape, labels shape, each features mean, each features standard deviation\n",
      "(35, 25, 6) (35, 6) 0.0182869084017 0.876730927485\n",
      "the dataset is therefore properly normalised, as expected.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "if __name__ == \"__main__\":\n",
    "    # -----------------------------\n",
    "    # Step 1: load and prepare data\n",
    "    # -----------------------------\n",
    "\n",
    "    # Those are separate normalised input features for the neural network\n",
    "    INPUT_SIGNAL_TYPES = [\n",
    "        \"body_acc_x_\",\n",
    "        \"body_acc_y_\",\n",
    "        \"body_acc_z_\",\n",
    "        \"body_gyro_x_\",\n",
    "        \"body_gyro_y_\",\n",
    "        \"body_gyro_z_\",\n",
    "        \"total_acc_x_\",\n",
    "        \"total_acc_y_\",\n",
    "        \"total_acc_z_\"\n",
    "    ]\n",
    "\n",
    "    # Output classes to learn how to classify\n",
    "    LABELS = [\n",
    "        \"WALKING\",\n",
    "        \"WALKING_UPSTAIRS\",\n",
    "        \"WALKING_DOWNSTAIRS\",\n",
    "        \"SITTING\",\n",
    "        \"STANDING\",\n",
    "        \"LAYING\"\n",
    "    ]\n",
    "\n",
    "    DATA_PATH = \"\"\n",
    "    DATASET_PATH = DATA_PATH + \"UCI HAR Dataset/\"\n",
    "    print(\"\\n\" + \"Dataset is now located at: \" + DATASET_PATH)\n",
    "    TRAIN = \"train/\"\n",
    "    TEST = \"test/\"\n",
    "\n",
    "    X_train_signals_paths = [\n",
    "        DATASET_PATH + TRAIN + \"Inertial Signals/\" + signal + \"train.txt\" for signal in INPUT_SIGNAL_TYPES\n",
    "    ]\n",
    "    X_test_signals_paths = [\n",
    "        DATASET_PATH + TEST + \"Inertial Signals/\" + signal + \"test.txt\" for signal in INPUT_SIGNAL_TYPES\n",
    "    ]\n",
    "    testdata=['sit1.txt','sit2.txt','sit3.txt','stand1.txt','stand2.txt','stand3.txt']\n",
    "    X_train = load_X(X_train_signals_paths)\n",
    "    k=0.0\n",
    "    for i in range(128-128//5):\n",
    "        k=k+0.2\n",
    "        X_train=np.delete(X_train,int(k),axis=1)\n",
    "    X_train=np.delete(X_train,(6,7,8),axis=2)\n",
    "    print(np.shape(X_train))\n",
    "    \n",
    "    #X_test = load_X(X_test_signals_paths)\n",
    "    #print(X_train[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #X_test=np.delete(X_test,(0,1,2),axis=2)\n",
    "    testpath='data_new_2912/'\n",
    "    X_test=pd.read_csv(testpath+\"sit1.csv\",names=[\"body_acc_x_\",\n",
    "        \"body_acc_y_\",\n",
    "        \"body_acc_z_\",\n",
    "        \"body_gyro_x_\",\n",
    "        \"body_gyro_y_\",\n",
    "        \"body_gyro_z_\",'sa','12'])\n",
    "    #np.delete(X_test,6)\n",
    "    #X_test=np.array(X_test)\n",
    "    X_test=X_test.drop(X_test.columns[[6,7]], axis=1)\n",
    "    X_test=X_test.drop(X_test.index[[875,876,877,878]])\n",
    "    print(X_test.shape)\n",
    "    X_test=X_test.values\n",
    "    print(X_test[24])\n",
    "    X_test=np.reshape(X_test,((35,25,6)))\n",
    "    print(X_test[0])\n",
    "    print(X_test.shape)\n",
    "    '''X_test=pd.read_csv(testpath+\"sit2.csv\",names=[\"body_acc_x_\",\n",
    "        \"body_acc_y_\",\n",
    "        \"body_acc_z_\",\n",
    "        \"body_gyro_x_\",\n",
    "        \"body_gyro_y_\",\n",
    "        \"body_gyro_z_\",'sa','12'])\n",
    "    print(X_test.shape)\n",
    "    #np.delete(X_test,6)\n",
    "    #X_test=np.array(X_test)\n",
    "    X_test=X_test.drop(X_test.columns[[6,7]], axis=1)\n",
    "    X_test=X_test.drop(X_test.index[[625,626,627,628,629,630]])\n",
    "    print(X_test.shape)\n",
    "    X_test=X_test.values\n",
    "    X_test=np.reshape(X_test,((25,25,6)))\n",
    "    print(X_test.shape)'''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    y_train_path = DATASET_PATH + TRAIN + \"y_train.txt\"\n",
    "    #y_test_path = DATASET_PATH + TEST + \"y_test.txt\"\n",
    "    y_train = one_hot(load_y(y_train_path))\n",
    "    #y_test = one_hot(load_y(y_test_path))\n",
    "    y_test=np.zeros((35,6))\n",
    "    y_test[:,4]=1\n",
    "    print(y_test)\n",
    "    \n",
    "    \n",
    "    config = Config(X_train, X_test)\n",
    "    print(\"Some useful info to get an insight on dataset's shape and normalisation:\")\n",
    "    print(\"features shape, labels shape, each features mean, each features standard deviation\")\n",
    "    print(X_test.shape, y_test.shape,\n",
    "          np.mean(X_test), np.std(X_test))\n",
    "    print(\"the dataset is therefore properly normalised, as expected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    X = tf.placeholder(tf.float32, [None, config.n_steps, config.n_inputs])\n",
    "    Y = tf.placeholder(tf.float32, [None, config.n_classes])\n",
    "\n",
    "    pred_Y = LSTM_Network(X, config)\n",
    "\n",
    "    # Loss,optimizer,evaluation\n",
    "    l2 = config.lambda_loss_amount * \\\n",
    "        sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\n",
    "    # Softmax loss and L2\n",
    "    cost = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=pred_Y)) + l2\n",
    "    optimizer = tf.train.AdamOptimizer(\n",
    "        learning_rate=config.learning_rate).minimize(cost)\n",
    "\n",
    "    correct_pred = tf.equal(tf.argmax(pred_Y, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traing iter: 0, test accuracy : 0.4571428596973419, loss : 1.9989497661590576\n",
      "traing iter: 1, test accuracy : 0.02857142873108387, loss : 2.281069040298462\n",
      "traing iter: 2, test accuracy : 0.02857142873108387, loss : 2.305429697036743\n",
      "traing iter: 3, test accuracy : 0.02857142873108387, loss : 2.546128511428833\n",
      "traing iter: 4, test accuracy : 0.0, loss : 3.471855640411377\n",
      "traing iter: 5, test accuracy : 0.08571428805589676, loss : 4.492760181427002\n",
      "traing iter: 6, test accuracy : 0.05714285746216774, loss : 5.664357662200928\n",
      "traing iter: 7, test accuracy : 0.0, loss : 6.528818607330322\n",
      "traing iter: 8, test accuracy : 0.05714285746216774, loss : 6.753074645996094\n",
      "traing iter: 9, test accuracy : 0.0, loss : 7.258989334106445\n",
      "traing iter: 10, test accuracy : 0.0, loss : 7.433203220367432\n",
      "traing iter: 11, test accuracy : 0.0, loss : 7.50606107711792\n",
      "traing iter: 12, test accuracy : 0.0, loss : 7.61952543258667\n",
      "traing iter: 13, test accuracy : 0.0, loss : 7.924055099487305\n",
      "traing iter: 14, test accuracy : 0.0, loss : 7.874031066894531\n",
      "traing iter: 15, test accuracy : 0.0, loss : 7.945167541503906\n",
      "traing iter: 16, test accuracy : 0.0, loss : 7.693666458129883\n",
      "traing iter: 17, test accuracy : 0.0, loss : 7.84653377532959\n",
      "traing iter: 18, test accuracy : 0.0, loss : 7.914376735687256\n",
      "traing iter: 19, test accuracy : 0.0, loss : 8.017664909362793\n",
      "traing iter: 20, test accuracy : 0.0, loss : 7.876317501068115\n",
      "traing iter: 21, test accuracy : 0.0, loss : 7.808344841003418\n",
      "traing iter: 22, test accuracy : 0.0, loss : 8.065086364746094\n",
      "traing iter: 23, test accuracy : 0.0, loss : 8.059097290039062\n",
      "traing iter: 24, test accuracy : 0.0, loss : 8.046952247619629\n",
      "traing iter: 25, test accuracy : 0.0, loss : 7.8058671951293945\n",
      "traing iter: 26, test accuracy : 0.0, loss : 8.03065013885498\n",
      "traing iter: 27, test accuracy : 0.0, loss : 7.91828727722168\n",
      "traing iter: 28, test accuracy : 0.0, loss : 8.048383712768555\n",
      "traing iter: 29, test accuracy : 0.0, loss : 7.717740058898926\n",
      "traing iter: 30, test accuracy : 0.0, loss : 7.9898681640625\n",
      "traing iter: 31, test accuracy : 0.0, loss : 7.697636604309082\n",
      "traing iter: 32, test accuracy : 0.0, loss : 7.880130290985107\n",
      "traing iter: 33, test accuracy : 0.0, loss : 7.956003665924072\n",
      "traing iter: 34, test accuracy : 0.0, loss : 7.917606830596924\n",
      "traing iter: 35, test accuracy : 0.0, loss : 7.9903388023376465\n",
      "traing iter: 36, test accuracy : 0.0, loss : 7.727289199829102\n",
      "traing iter: 37, test accuracy : 0.0, loss : 7.804933071136475\n",
      "traing iter: 38, test accuracy : 0.0, loss : 7.825976848602295\n",
      "traing iter: 39, test accuracy : 0.0, loss : 8.156153678894043\n",
      "traing iter: 40, test accuracy : 0.0, loss : 7.968667507171631\n",
      "traing iter: 41, test accuracy : 0.0, loss : 8.26828670501709\n",
      "traing iter: 42, test accuracy : 0.0, loss : 8.37760066986084\n",
      "traing iter: 43, test accuracy : 0.0, loss : 8.515819549560547\n",
      "traing iter: 44, test accuracy : 0.0, loss : 8.234638214111328\n",
      "traing iter: 45, test accuracy : 0.0, loss : 8.2001371383667\n",
      "traing iter: 46, test accuracy : 0.0, loss : 8.009247779846191\n",
      "traing iter: 47, test accuracy : 0.0, loss : 8.05604362487793\n",
      "traing iter: 48, test accuracy : 0.02857142873108387, loss : 7.2514543533325195\n",
      "traing iter: 49, test accuracy : 0.0, loss : 8.124626159667969\n",
      "traing iter: 50, test accuracy : 0.0, loss : 7.6399455070495605\n",
      "traing iter: 51, test accuracy : 0.0, loss : 7.624373912811279\n",
      "traing iter: 52, test accuracy : 0.0, loss : 7.961965560913086\n",
      "traing iter: 53, test accuracy : 0.0, loss : 7.864591598510742\n",
      "traing iter: 54, test accuracy : 0.0, loss : 8.188508987426758\n",
      "traing iter: 55, test accuracy : 0.0, loss : 8.07701301574707\n",
      "traing iter: 56, test accuracy : 0.0, loss : 8.834324836730957\n",
      "traing iter: 57, test accuracy : 0.0, loss : 8.529985427856445\n",
      "traing iter: 58, test accuracy : 0.0, loss : 7.883052825927734\n",
      "traing iter: 59, test accuracy : 0.0, loss : 7.945558071136475\n",
      "traing iter: 60, test accuracy : 0.0, loss : 7.799341201782227\n",
      "traing iter: 61, test accuracy : 0.0, loss : 7.893060684204102\n",
      "traing iter: 62, test accuracy : 0.0, loss : 7.853850841522217\n",
      "traing iter: 63, test accuracy : 0.0, loss : 8.058667182922363\n",
      "traing iter: 64, test accuracy : 0.0, loss : 8.394755363464355\n",
      "traing iter: 65, test accuracy : 0.0, loss : 8.313563346862793\n",
      "traing iter: 66, test accuracy : 0.0, loss : 8.353114128112793\n",
      "traing iter: 67, test accuracy : 0.0, loss : 8.602792739868164\n",
      "traing iter: 68, test accuracy : 0.0, loss : 8.689521789550781\n",
      "traing iter: 69, test accuracy : 0.02857142873108387, loss : 8.042966842651367\n",
      "traing iter: 70, test accuracy : 0.0, loss : 8.731756210327148\n",
      "traing iter: 71, test accuracy : 0.02857142873108387, loss : 8.362792015075684\n",
      "traing iter: 72, test accuracy : 0.0, loss : 8.597381591796875\n",
      "traing iter: 73, test accuracy : 0.0, loss : 8.202335357666016\n",
      "traing iter: 74, test accuracy : 0.0, loss : 8.14730453491211\n",
      "traing iter: 75, test accuracy : 0.0, loss : 8.460741996765137\n",
      "traing iter: 76, test accuracy : 0.0, loss : 8.194723129272461\n",
      "traing iter: 77, test accuracy : 0.0, loss : 8.065340995788574\n",
      "traing iter: 78, test accuracy : 0.0, loss : 8.534830093383789\n",
      "traing iter: 79, test accuracy : 0.0, loss : 8.9537992477417\n",
      "traing iter: 80, test accuracy : 0.0, loss : 8.532955169677734\n",
      "traing iter: 81, test accuracy : 0.0, loss : 7.971266746520996\n",
      "traing iter: 82, test accuracy : 0.0, loss : 8.763182640075684\n",
      "traing iter: 83, test accuracy : 0.0, loss : 8.288989067077637\n",
      "traing iter: 84, test accuracy : 0.0, loss : 8.357185363769531\n",
      "traing iter: 85, test accuracy : 0.0, loss : 8.184839248657227\n",
      "traing iter: 86, test accuracy : 0.0, loss : 8.380261421203613\n",
      "traing iter: 87, test accuracy : 0.0, loss : 8.02196216583252\n",
      "traing iter: 88, test accuracy : 0.0, loss : 8.129264831542969\n",
      "traing iter: 89, test accuracy : 0.0, loss : 8.356575012207031\n",
      "traing iter: 90, test accuracy : 0.0, loss : 8.49826431274414\n",
      "traing iter: 91, test accuracy : 0.0, loss : 8.6699800491333\n",
      "traing iter: 92, test accuracy : 0.0, loss : 8.709626197814941\n",
      "traing iter: 93, test accuracy : 0.0, loss : 8.568953514099121\n",
      "traing iter: 94, test accuracy : 0.0, loss : 8.660382270812988\n",
      "traing iter: 95, test accuracy : 0.0, loss : 8.67818832397461\n",
      "traing iter: 96, test accuracy : 0.0, loss : 8.468485832214355\n",
      "traing iter: 97, test accuracy : 0.0, loss : 8.252650260925293\n",
      "traing iter: 98, test accuracy : 0.0, loss : 8.563803672790527\n",
      "traing iter: 99, test accuracy : 0.0, loss : 8.785993576049805\n",
      "traing iter: 100, test accuracy : 0.0, loss : 8.383971214294434\n",
      "traing iter: 101, test accuracy : 0.0, loss : 8.367222785949707\n",
      "traing iter: 102, test accuracy : 0.0, loss : 8.372957229614258\n",
      "traing iter: 103, test accuracy : 0.0, loss : 8.61746597290039\n",
      "traing iter: 104, test accuracy : 0.0, loss : 8.482992172241211\n",
      "traing iter: 105, test accuracy : 0.0, loss : 8.578091621398926\n",
      "traing iter: 106, test accuracy : 0.0, loss : 8.607640266418457\n",
      "traing iter: 107, test accuracy : 0.02857142873108387, loss : 7.958025932312012\n",
      "traing iter: 108, test accuracy : 0.0, loss : 8.646313667297363\n",
      "traing iter: 109, test accuracy : 0.0, loss : 8.800542831420898\n",
      "traing iter: 110, test accuracy : 0.0, loss : 8.692822456359863\n",
      "traing iter: 111, test accuracy : 0.0, loss : 8.711285591125488\n",
      "traing iter: 112, test accuracy : 0.0, loss : 8.330952644348145\n",
      "traing iter: 113, test accuracy : 0.0, loss : 8.4807767868042\n",
      "traing iter: 114, test accuracy : 0.0, loss : 8.541128158569336\n",
      "traing iter: 115, test accuracy : 0.0, loss : 8.050989151000977\n",
      "traing iter: 116, test accuracy : 0.0, loss : 8.506824493408203\n",
      "traing iter: 117, test accuracy : 0.0, loss : 8.514111518859863\n",
      "traing iter: 118, test accuracy : 0.0, loss : 8.153656005859375\n",
      "traing iter: 119, test accuracy : 0.0, loss : 8.522527694702148\n",
      "traing iter: 120, test accuracy : 0.0, loss : 8.493961334228516\n",
      "traing iter: 121, test accuracy : 0.0, loss : 8.860577583312988\n",
      "traing iter: 122, test accuracy : 0.0, loss : 8.85639762878418\n",
      "traing iter: 123, test accuracy : 0.0, loss : 8.891584396362305\n",
      "traing iter: 124, test accuracy : 0.0, loss : 8.962141036987305\n",
      "traing iter: 125, test accuracy : 0.02857142873108387, loss : 8.360459327697754\n",
      "traing iter: 126, test accuracy : 0.0, loss : 8.261967658996582\n",
      "traing iter: 127, test accuracy : 0.0, loss : 8.010357856750488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traing iter: 128, test accuracy : 0.0, loss : 8.374369621276855\n",
      "traing iter: 129, test accuracy : 0.0, loss : 8.191486358642578\n",
      "traing iter: 130, test accuracy : 0.0, loss : 8.445229530334473\n",
      "traing iter: 131, test accuracy : 0.0, loss : 8.489704132080078\n",
      "traing iter: 132, test accuracy : 0.0, loss : 8.392037391662598\n",
      "traing iter: 133, test accuracy : 0.0, loss : 8.6050386428833\n",
      "traing iter: 134, test accuracy : 0.02857142873108387, loss : 8.45052433013916\n",
      "traing iter: 135, test accuracy : 0.0, loss : 8.562878608703613\n",
      "traing iter: 136, test accuracy : 0.0, loss : 8.759860038757324\n",
      "traing iter: 137, test accuracy : 0.02857142873108387, loss : 8.158563613891602\n",
      "traing iter: 138, test accuracy : 0.0, loss : 8.602044105529785\n",
      "traing iter: 139, test accuracy : 0.0, loss : 8.503076553344727\n",
      "traing iter: 140, test accuracy : 0.0, loss : 8.035380363464355\n",
      "traing iter: 141, test accuracy : 0.0, loss : 8.581905364990234\n",
      "traing iter: 142, test accuracy : 0.0, loss : 8.504890441894531\n",
      "traing iter: 143, test accuracy : 0.0, loss : 8.340618133544922\n",
      "traing iter: 144, test accuracy : 0.0, loss : 8.33360481262207\n",
      "traing iter: 145, test accuracy : 0.0, loss : 8.26819133758545\n",
      "traing iter: 146, test accuracy : 0.0, loss : 8.52949047088623\n",
      "traing iter: 147, test accuracy : 0.0, loss : 8.76088809967041\n",
      "traing iter: 148, test accuracy : 0.0, loss : 8.660552024841309\n",
      "traing iter: 149, test accuracy : 0.02857142873108387, loss : 8.197319984436035\n",
      "traing iter: 150, test accuracy : 0.0, loss : 8.044846534729004\n",
      "traing iter: 151, test accuracy : 0.0, loss : 8.292298316955566\n",
      "traing iter: 152, test accuracy : 0.0, loss : 8.336454391479492\n",
      "traing iter: 153, test accuracy : 0.0, loss : 8.130321502685547\n",
      "traing iter: 154, test accuracy : 0.0, loss : 7.848917007446289\n",
      "traing iter: 155, test accuracy : 0.02857142873108387, loss : 7.775486946105957\n",
      "traing iter: 156, test accuracy : 0.0, loss : 8.774737358093262\n",
      "traing iter: 157, test accuracy : 0.0, loss : 8.446967124938965\n",
      "traing iter: 158, test accuracy : 0.0, loss : 8.416293144226074\n",
      "traing iter: 159, test accuracy : 0.0, loss : 8.29652214050293\n",
      "traing iter: 160, test accuracy : 0.0, loss : 8.559319496154785\n",
      "traing iter: 161, test accuracy : 0.0, loss : 8.265155792236328\n",
      "traing iter: 162, test accuracy : 0.0, loss : 8.492949485778809\n",
      "traing iter: 163, test accuracy : 0.0, loss : 7.9273834228515625\n",
      "traing iter: 164, test accuracy : 0.0, loss : 8.474984169006348\n",
      "traing iter: 165, test accuracy : 0.0, loss : 8.463038444519043\n",
      "traing iter: 166, test accuracy : 0.0, loss : 8.39805793762207\n",
      "traing iter: 167, test accuracy : 0.0, loss : 8.854135513305664\n",
      "traing iter: 168, test accuracy : 0.0, loss : 9.158318519592285\n",
      "traing iter: 169, test accuracy : 0.0, loss : 8.655186653137207\n",
      "traing iter: 170, test accuracy : 0.0, loss : 8.744282722473145\n",
      "traing iter: 171, test accuracy : 0.0, loss : 8.508625030517578\n",
      "traing iter: 172, test accuracy : 0.0, loss : 8.726548194885254\n",
      "traing iter: 173, test accuracy : 0.0, loss : 8.844551086425781\n",
      "traing iter: 174, test accuracy : 0.0, loss : 8.597474098205566\n",
      "traing iter: 175, test accuracy : 0.0, loss : 8.470968246459961\n",
      "traing iter: 176, test accuracy : 0.0, loss : 9.090228080749512\n",
      "traing iter: 177, test accuracy : 0.0, loss : 8.522292137145996\n",
      "traing iter: 178, test accuracy : 0.0, loss : 9.030208587646484\n",
      "traing iter: 179, test accuracy : 0.0, loss : 7.954476356506348\n",
      "traing iter: 180, test accuracy : 0.0, loss : 8.636622428894043\n",
      "traing iter: 181, test accuracy : 0.0, loss : 7.7684197425842285\n",
      "traing iter: 182, test accuracy : 0.0, loss : 8.806031227111816\n",
      "traing iter: 183, test accuracy : 0.0, loss : 8.369629859924316\n",
      "traing iter: 184, test accuracy : 0.0, loss : 8.46487808227539\n",
      "traing iter: 185, test accuracy : 0.0, loss : 8.673664093017578\n",
      "traing iter: 186, test accuracy : 0.0, loss : 8.662348747253418\n",
      "traing iter: 187, test accuracy : 0.0, loss : 8.713586807250977\n",
      "traing iter: 188, test accuracy : 0.0, loss : 8.77599048614502\n",
      "traing iter: 189, test accuracy : 0.0, loss : 8.949416160583496\n",
      "traing iter: 190, test accuracy : 0.02857142873108387, loss : 8.999378204345703\n",
      "traing iter: 191, test accuracy : 0.0, loss : 8.90774154663086\n",
      "traing iter: 192, test accuracy : 0.0, loss : 8.84689712524414\n",
      "traing iter: 193, test accuracy : 0.02857142873108387, loss : 8.622825622558594\n",
      "traing iter: 194, test accuracy : 0.02857142873108387, loss : 9.223577499389648\n",
      "traing iter: 195, test accuracy : 0.0, loss : 8.905472755432129\n",
      "traing iter: 196, test accuracy : 0.0, loss : 9.026790618896484\n",
      "traing iter: 197, test accuracy : 0.0, loss : 8.896469116210938\n",
      "traing iter: 198, test accuracy : 0.0, loss : 8.872740745544434\n",
      "traing iter: 199, test accuracy : 0.0, loss : 8.636167526245117\n",
      "traing iter: 200, test accuracy : 0.0, loss : 8.8449068069458\n",
      "traing iter: 201, test accuracy : 0.0, loss : 8.503623008728027\n",
      "traing iter: 202, test accuracy : 0.0, loss : 8.811484336853027\n",
      "traing iter: 203, test accuracy : 0.0, loss : 8.72612190246582\n",
      "traing iter: 204, test accuracy : 0.0, loss : 8.713309288024902\n",
      "traing iter: 205, test accuracy : 0.0, loss : 8.824599266052246\n",
      "traing iter: 206, test accuracy : 0.0, loss : 8.97337532043457\n",
      "traing iter: 207, test accuracy : 0.0, loss : 8.640759468078613\n",
      "traing iter: 208, test accuracy : 0.0, loss : 8.847183227539062\n",
      "traing iter: 209, test accuracy : 0.0, loss : 8.676665306091309\n",
      "traing iter: 210, test accuracy : 0.0, loss : 8.718138694763184\n",
      "traing iter: 211, test accuracy : 0.0, loss : 9.024190902709961\n",
      "traing iter: 212, test accuracy : 0.0, loss : 8.646547317504883\n",
      "traing iter: 213, test accuracy : 0.0, loss : 8.901576042175293\n",
      "traing iter: 214, test accuracy : 0.0, loss : 8.69786548614502\n",
      "traing iter: 215, test accuracy : 0.0, loss : 8.85481071472168\n",
      "traing iter: 216, test accuracy : 0.0, loss : 8.991209983825684\n",
      "traing iter: 217, test accuracy : 0.0, loss : 8.552547454833984\n",
      "traing iter: 218, test accuracy : 0.0, loss : 8.822286605834961\n",
      "traing iter: 219, test accuracy : 0.0, loss : 8.604015350341797\n",
      "traing iter: 220, test accuracy : 0.0, loss : 8.866704940795898\n",
      "traing iter: 221, test accuracy : 0.0, loss : 8.870317459106445\n",
      "traing iter: 222, test accuracy : 0.0, loss : 8.891684532165527\n",
      "traing iter: 223, test accuracy : 0.0, loss : 8.796192169189453\n",
      "traing iter: 224, test accuracy : 0.0, loss : 8.80978012084961\n",
      "traing iter: 225, test accuracy : 0.0, loss : 8.82557487487793\n",
      "traing iter: 226, test accuracy : 0.0, loss : 8.892702102661133\n",
      "traing iter: 227, test accuracy : 0.0, loss : 9.034224510192871\n",
      "traing iter: 228, test accuracy : 0.0, loss : 8.866130828857422\n",
      "traing iter: 229, test accuracy : 0.0, loss : 9.008611679077148\n",
      "traing iter: 230, test accuracy : 0.0, loss : 9.054328918457031\n",
      "traing iter: 231, test accuracy : 0.0, loss : 9.059798240661621\n",
      "traing iter: 232, test accuracy : 0.02857142873108387, loss : 9.014206886291504\n",
      "traing iter: 233, test accuracy : 0.0, loss : 9.605324745178223\n",
      "traing iter: 234, test accuracy : 0.02857142873108387, loss : 9.097887992858887\n",
      "traing iter: 235, test accuracy : 0.0, loss : 8.228531837463379\n",
      "traing iter: 236, test accuracy : 0.0, loss : 7.5145344734191895\n",
      "traing iter: 237, test accuracy : 0.0, loss : 7.288074493408203\n",
      "traing iter: 238, test accuracy : 0.05714285746216774, loss : 6.681532859802246\n",
      "traing iter: 239, test accuracy : 0.02857142873108387, loss : 6.481822967529297\n",
      "traing iter: 240, test accuracy : 0.0, loss : 6.410173416137695\n",
      "traing iter: 241, test accuracy : 0.0, loss : 6.665259838104248\n",
      "traing iter: 242, test accuracy : 0.0, loss : 6.939625263214111\n",
      "traing iter: 243, test accuracy : 0.0, loss : 6.805850028991699\n",
      "traing iter: 244, test accuracy : 0.0, loss : 7.04525899887085\n",
      "traing iter: 245, test accuracy : 0.0, loss : 7.264520645141602\n",
      "traing iter: 246, test accuracy : 0.0, loss : 7.402864456176758\n",
      "traing iter: 247, test accuracy : 0.0, loss : 7.4800615310668945\n",
      "traing iter: 248, test accuracy : 0.0, loss : 7.5289082527160645\n",
      "traing iter: 249, test accuracy : 0.0, loss : 7.734772682189941\n",
      "traing iter: 250, test accuracy : 0.0, loss : 7.770859241485596\n",
      "traing iter: 251, test accuracy : 0.0, loss : 7.892991065979004\n",
      "traing iter: 252, test accuracy : 0.0, loss : 7.855055809020996\n",
      "traing iter: 253, test accuracy : 0.0, loss : 8.187828063964844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traing iter: 254, test accuracy : 0.0, loss : 7.989915370941162\n",
      "traing iter: 255, test accuracy : 0.0, loss : 8.0504789352417\n",
      "traing iter: 256, test accuracy : 0.02857142873108387, loss : 8.020362854003906\n",
      "traing iter: 257, test accuracy : 0.0, loss : 8.517203330993652\n",
      "traing iter: 258, test accuracy : 0.0, loss : 8.024763107299805\n",
      "traing iter: 259, test accuracy : 0.0, loss : 8.276910781860352\n",
      "traing iter: 260, test accuracy : 0.0, loss : 7.91554069519043\n",
      "traing iter: 261, test accuracy : 0.0, loss : 8.961153984069824\n",
      "traing iter: 262, test accuracy : 0.02857142873108387, loss : 8.534820556640625\n",
      "traing iter: 263, test accuracy : 0.0, loss : 8.101201057434082\n",
      "traing iter: 264, test accuracy : 0.0, loss : 8.211852073669434\n",
      "traing iter: 265, test accuracy : 0.0, loss : 8.410112380981445\n",
      "traing iter: 266, test accuracy : 0.0, loss : 7.998043060302734\n",
      "traing iter: 267, test accuracy : 0.0, loss : 7.9875030517578125\n",
      "traing iter: 268, test accuracy : 0.0, loss : 7.935380458831787\n",
      "traing iter: 269, test accuracy : 0.0, loss : 8.269311904907227\n",
      "traing iter: 270, test accuracy : 0.0, loss : 7.918211460113525\n",
      "traing iter: 271, test accuracy : 0.0, loss : 8.5576753616333\n",
      "traing iter: 272, test accuracy : 0.0, loss : 8.10863971710205\n",
      "traing iter: 273, test accuracy : 0.0, loss : 8.493319511413574\n",
      "traing iter: 274, test accuracy : 0.0, loss : 8.16899299621582\n",
      "traing iter: 275, test accuracy : 0.0, loss : 8.451075553894043\n",
      "traing iter: 276, test accuracy : 0.0, loss : 8.412843704223633\n",
      "traing iter: 277, test accuracy : 0.0, loss : 8.389789581298828\n",
      "traing iter: 278, test accuracy : 0.0, loss : 8.447296142578125\n",
      "traing iter: 279, test accuracy : 0.0, loss : 8.287766456604004\n",
      "traing iter: 280, test accuracy : 0.0, loss : 8.462762832641602\n",
      "traing iter: 281, test accuracy : 0.0, loss : 8.318082809448242\n",
      "traing iter: 282, test accuracy : 0.0, loss : 8.259258270263672\n",
      "traing iter: 283, test accuracy : 0.0, loss : 8.565752983093262\n",
      "traing iter: 284, test accuracy : 0.02857142873108387, loss : 8.05668830871582\n",
      "traing iter: 285, test accuracy : 0.0, loss : 8.39482593536377\n",
      "traing iter: 286, test accuracy : 0.0, loss : 8.414785385131836\n",
      "traing iter: 287, test accuracy : 0.0, loss : 8.099936485290527\n",
      "traing iter: 288, test accuracy : 0.0, loss : 8.263914108276367\n",
      "traing iter: 289, test accuracy : 0.0, loss : 8.189650535583496\n",
      "traing iter: 290, test accuracy : 0.0, loss : 8.651571273803711\n",
      "traing iter: 291, test accuracy : 0.0, loss : 8.525362014770508\n",
      "traing iter: 292, test accuracy : 0.0, loss : 8.498624801635742\n",
      "traing iter: 293, test accuracy : 0.0, loss : 8.466652870178223\n",
      "traing iter: 294, test accuracy : 0.02857142873108387, loss : 8.672741889953613\n",
      "traing iter: 295, test accuracy : 0.02857142873108387, loss : 8.574959754943848\n",
      "traing iter: 296, test accuracy : 0.0, loss : 8.91249942779541\n",
      "traing iter: 297, test accuracy : 0.0, loss : 8.487772941589355\n",
      "traing iter: 298, test accuracy : 0.0, loss : 8.692710876464844\n",
      "traing iter: 299, test accuracy : 0.02857142873108387, loss : 8.166830062866211\n",
      "\n",
      "final test accuracy: 0.02857142873108387\n",
      "best epoch's test accuracy: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=False))\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    y_pre=y_test[0]\n",
    "    best_accuracy = 0.0\n",
    "    # Start training for each batch and loop epochs\n",
    "    for i in range(config.training_epochs):\n",
    "        for start, end in zip(range(0, config.train_count, config.batch_size),\n",
    "                              range(config.batch_size, config.train_count + 1, config.batch_size)):\n",
    "            sess.run(optimizer, feed_dict={X: X_train[start:end],\n",
    "                                           Y: y_train[start:end]})\n",
    "\n",
    "        # Test completely at every epoch: calculate accuracy\n",
    "        pred_out, accuracy_out, loss_out = sess.run(\n",
    "            [pred_Y, accuracy, cost],\n",
    "            feed_dict={\n",
    "                X: X_test,\n",
    "                Y: y_test\n",
    "            }\n",
    "        )\n",
    "        print(\"traing iter: {},\".format(i) +\n",
    "              \" test accuracy : {},\".format(accuracy_out) +\n",
    "              \" loss : {}\".format(loss_out))\n",
    "        if accuracy_out>best_accuracy:\n",
    "            y_pre=pred_out\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"final test accuracy: {}\".format(accuracy_out))\n",
    "    print(\"best epoch's test accuracy: {}\".format(best_accuracy))\n",
    "    print(\"\")   \n",
    "    best_accuracy = max(best_accuracy, accuracy_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]]\n",
      "Col 0\n",
      "[[34  1]\n",
      " [ 0  0]]\n",
      "\n",
      "Col 1\n",
      "[[22 13]\n",
      " [ 0  0]]\n",
      "\n",
      "Col 2\n",
      "[[16 19]\n",
      " [ 0  0]]\n",
      "\n",
      "Col 3\n",
      "[[35]]\n",
      "\n",
      "Col 4\n",
      "[[ 0  0]\n",
      " [34  1]]\n",
      "\n",
      "Col 5\n",
      "[[34  1]\n",
      " [ 0  0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b = np.zeros_like(y_pre)\n",
    "b[np.arange(len(y_pre)), y_pre.argmax(1)] = 1\n",
    "y_pre=b\n",
    "print(y_pre)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "for i in range(y_test.shape[1]):\n",
    "    print(\"Col {}\".format(i))\n",
    "    print(confusion_matrix(y_test[:,i], y_pre[:,i]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: Tensor(\"mul_1:0\", shape=(), dtype=float32)%\n",
      "\n",
      "Precision: 100.0%\n",
      "Recall: 2.857142857142857%\n",
      "f1_score: 5.555555555555556%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 1 13 19  1  1]\n",
      " [ 0  0  0  0  0]]\n",
      "\n",
      "Confusion matrix (normalised to % of total test data):\n",
      "[[  0.           0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.        ]\n",
      " [  2.85714293  37.1428566   54.28571701   2.85714293   2.85714293]\n",
      " [  0.           0.           0.           0.           0.        ]]\n",
      "Note: training and testing data is not equally distributed amongst classes, \n",
      "so it is normal that more than a 6th of the data is correctly classifier in the last category.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\naru_piece\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\naru_piece\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "c:\\users\\naru_piece\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\naru_piece\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e00361cc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "predictions = y_pre\n",
    "\n",
    "print(\"Testing Accuracy: {}%\".format(100*accuracy))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Precision: {}%\".format(100*metrics.precision_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"Recall: {}%\".format(100*metrics.recall_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"f1_score: {}%\".format(100*metrics.f1_score(y_test, predictions, average=\"weighted\")))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix:\")\n",
    "confusion_matrix = metrics.confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))\n",
    "print(confusion_matrix)\n",
    "normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion matrix (normalised to % of total test data):\")\n",
    "print(normalised_confusion_matrix)\n",
    "print(\"Note: training and testing data is not equally distributed amongst classes, \")\n",
    "print(\"so it is normal that more than a 6th of the data is correctly classifier in the last category.\")\n",
    "%matplotlib inline\n",
    "# Plot Results: \n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.imshow(\n",
    "    normalised_confusion_matrix, \n",
    "    interpolation='nearest', \n",
    "    cmap=plt.cm.rainbow\n",
    ")\n",
    "plt.title(\"Confusion matrix \\n(normalised to % of total test data)\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(n_classes)\n",
    "plt.xticks(tick_marks, LABELS, rotation=90)\n",
    "plt.yticks(tick_marks, LABELS)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
