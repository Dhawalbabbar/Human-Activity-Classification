{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_X(X_signals_paths):\n",
    "    X_signals = []\n",
    "\n",
    "    for signal_type_path in X_signals_paths:\n",
    "        file = open(signal_type_path, 'r')\n",
    "        # Read dataset from disk, dealing with text files' syntax\n",
    "        X_signals.append(\n",
    "            [np.array(serie, dtype=np.float32) for serie in [\n",
    "                row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "            ]]\n",
    "        )\n",
    "        file.close()\n",
    "\n",
    "    return np.transpose(np.array(X_signals), (1, 2, 0))\n",
    "\n",
    "\n",
    "# Load \"y\" (the neural network's training and testing outputs)\n",
    "\n",
    "def load_y(y_path):\n",
    "    file = open(y_path, 'r')\n",
    "    # Read dataset from disk, dealing with text file's syntax\n",
    "    y_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "        ]],\n",
    "        dtype=np.int32\n",
    "    )\n",
    "    file.close()\n",
    "    # Substract 1 to each output class for friendly 0-based indexing\n",
    "    return y_ - 1\n",
    "\n",
    "def one_hot(y_):\n",
    "    \"\"\"\n",
    "    Function to encode output labels from number indexes.\n",
    "    E.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
    "    \"\"\"\n",
    "    y_ = y_.reshape(len(y_))\n",
    "    n_values = int(np.max(y_)) + 1\n",
    "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    \"\"\"\n",
    "    define a class to store parameters,\n",
    "    the input should be feature mat of training and testing\n",
    "    Note: it would be more interesting to use a HyperOpt search space:\n",
    "    https://github.com/hyperopt/hyperopt\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_train, X_test):\n",
    "        # Input data\n",
    "        self.train_count = len(X_train)  # 7352 training series\n",
    "        self.test_data_count = len(X_test)  # 2947 testing series\n",
    "        self.n_steps = len(X_train[0])  # 128 time_steps per series\n",
    "\n",
    "        # Training\n",
    "        self.learning_rate = 0.00005\n",
    "        self.lambda_loss_amount = 0.00005\n",
    "        self.training_epochs = 500\n",
    "        self.batch_size = 100\n",
    "        \n",
    "        learning_rate = 0.0025\n",
    "        lambda_loss_amount = 0.0015\n",
    "        training_iters = training_data_count * 300  # Loop 300 times on the dataset\n",
    "        batch_size = 1500\n",
    "        display_iter = 30000 \n",
    "\n",
    "        # LSTM structure\n",
    "        self.n_inputs = len(X_train[0][0])  # Features count is of 9: 3 * 3D sensors features over time\n",
    "        self.n_hidden = 40  # nb of neurons inside the neural network\n",
    "        self.n_classes = 2  # Final output classes\n",
    "        self.W = {\n",
    "            'hidden': tf.Variable(tf.random_normal([self.n_inputs, self.n_hidden])),\n",
    "            'output': tf.Variable(tf.random_normal([self.n_hidden, self.n_classes]))\n",
    "        }\n",
    "        self.biases = {\n",
    "            'hidden': tf.Variable(tf.random_normal([self.n_hidden], mean=1.0)),\n",
    "            'output': tf.Variable(tf.random_normal([self.n_classes]))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Network(_X, config):\n",
    "    \"\"\"Function returns a TensorFlow RNN with two stacked LSTM cells\n",
    "    Two LSTM cells are stacked which adds deepness to the neural network.\n",
    "    Note, some code of this notebook is inspired from an slightly different\n",
    "    RNN architecture used on another dataset, some of the credits goes to\n",
    "    \"aymericdamien\".\n",
    "    Args:\n",
    "        _X:     ndarray feature matrix, shape: [batch_size, time_steps, n_inputs]\n",
    "        config: Config for the neural network.\n",
    "    Returns:\n",
    "        This is a description of what is returned.\n",
    "    Raises:\n",
    "        KeyError: Raises an exception.\n",
    "      Args:\n",
    "        feature_mat: ndarray fature matrix, shape=[batch_size,time_steps,n_inputs]\n",
    "        config: class containing config of network\n",
    "      return:\n",
    "              : matrix  output shape [batch_size,n_classes]\n",
    "    \"\"\"\n",
    "    # (NOTE: This step could be greatly optimised by shaping the dataset once\n",
    "    # input shape: (batch_size, n_steps, n_input)\n",
    "    _X = tf.transpose(_X, [1, 0, 2])  # permute n_steps and batch_size\n",
    "    # Reshape to prepare input to hidden activation\n",
    "    _X = tf.reshape(_X, [-1, config.n_inputs])\n",
    "    # new shape: (n_steps*batch_size, n_input)\n",
    "\n",
    "    # Linear activation\n",
    "    _X = tf.nn.relu(tf.matmul(_X, config.W['hidden']) + config.biases['hidden'])\n",
    "    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "    _X = tf.split(_X, config.n_steps, 0)\n",
    "    # new shape: n_steps * (batch_size, n_hidden)\n",
    "\n",
    "    # Define two stacked LSTM cells (two recurrent layers deep) with tensorflow\n",
    "    lstm_cell_1 = tf.contrib.rnn.BasicLSTMCell(config.n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "    lstm_cell_2 = tf.contrib.rnn.BasicLSTMCell(config.n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "    lstm_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell_1, lstm_cell_2], state_is_tuple=True)\n",
    "    # Get LSTM cell output\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(lstm_cells, _X, dtype=tf.float32)\n",
    "\n",
    "    # Get last time step's output feature for a \"many to one\" style classifier,\n",
    "    # as in the image describing RNNs at the top of this page\n",
    "    lstm_last_output = outputs[-1]\n",
    "\n",
    "    # Linear activation\n",
    "    return tf.matmul(lstm_last_output, config.W['output']) + config.biases['output']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2614, 100, 6)\n",
      "Some useful info to get an insight on dataset's shape and normalisation:\n",
      "features shape, labels shape, each features mean, each features standard deviation\n",
      "(1288, 100, 6) (1288, 2) -0.00306312191641 0.424876835798\n",
      "the dataset is therefore properly normalised, as expected.\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "if __name__ == \"__main__\":\n",
    "    # -----------------------------\n",
    "    # Step 1: load and prepare data\n",
    "    # -----------------------------\n",
    "\n",
    "    # Those are separate normalised input features for the neural network\n",
    "    INPUT_SIGNAL_TYPES = [\n",
    "        \"body_acc_x_\",\n",
    "        \"body_acc_y_\",\n",
    "        \"body_acc_z_\",\n",
    "        \"body_gyro_x_\",\n",
    "        \"body_gyro_y_\",\n",
    "        \"body_gyro_z_\",\n",
    "        \"total_acc_x_\",\n",
    "        \"total_acc_y_\",\n",
    "        \"total_acc_z_\"\n",
    "    ]\n",
    "\n",
    "    # Output classes to learn how to classify\n",
    "    LABELS = [\n",
    "        \"SITTING\",\n",
    "        \"STANDING\",\n",
    "    ]\n",
    "    files=['sess002','sess003','sess004','sess005','sess006','sess007','sess008','sess009','sess010','sess011','sess012','sess013','sess014','sess015','sess016','sess017','sess018','sess019','sess020']\n",
    "    values=[0,1,1,0,1,0,1,1,1,0,0,1,1,1,0,1,0,1,0,0]\n",
    "    j=0\n",
    "    #Loadind data\n",
    "    n_features=6\n",
    "    features = ['head_velocity_x','head_velocity_y','head_velocity_z','head_ang_velocity_x','head_ang_velocity_y','head_ang_velocity_z']\n",
    "    window=10\n",
    "    \n",
    "    X = pd.read_csv('OculusData/'+'sess001' ,names=['time','head_position_x','head_position_y','head_position_z','head_velocity_x','head_velocity_y','head_velocity_z','head_acc_x','head_acc_y','head_acc_z','head_orientation_x','head_orientation_y','head_orientation_z','head_orientation_w','head_ang_velocity_x','head_ang_velocity_y','head_ang_velocity_z','head_ang_acc_x','head_ang_acc_y','head_ang_acc_z','left_hand_position_x','left_hand_position_y','left_hand_position_z','left_hand_velocity_x','left_hand_velocity_y','left_hand_velocity_z','left_hand_acc_x','left_hand_acc_y','left_hand_acc_z','left_hand_orientation_x','left_hand_orientation_y','left_hand_orientation_z','left_hand_orientation_w','left_hand_ang_velocity_x','left_hand_ang_velocity_y','left_hand_ang_velocity_z','left_hand_ang_acc_x','left_hand_ang_acc_y','left_hand_ang_acc_z','right_hand_position_x','right_hand_position_y','right_hand_position_z','right_hand_velocity_x','right_hand_velocity_y','right_hand_velocity_z','right_hand_acc_x','right_hand_acc_y','right_hand_acc_z','right_hand_orientation_x','right_hand_orientation_y','right_hand_orientation_z','right_hand_orientation_w','right_hand_ang_velocity_x','right_hand_ang_velocity_y','right_hand_ang_velocity_z','right_hand_ang_acc_x','right_hand_ang_acc_y','right_hand_ang_acc_z'])\n",
    "    X=X[features]\n",
    "    data_points=X.shape[0]//window\n",
    "    #print(data_points)\n",
    "    X=X.head(data_points*window)\n",
    "    X=np.array(X)\n",
    "    X=np.reshape(X,((data_points,window,n_features)))\n",
    "    #print(X.shape)\n",
    "    Y=np.zeros((data_points,2))\n",
    "    Y[:,values[j]]=1\n",
    "    j+=1\n",
    "    \n",
    "    for i in files:\n",
    "        X0 = pd.read_csv('OculusData/'+i ,names=['time','head_position_x','head_position_y','head_position_z','head_velocity_x','head_velocity_y','head_velocity_z','head_acc_x','head_acc_y','head_acc_z','head_orientation_x','head_orientation_y','head_orientation_z','head_orientation_w','head_ang_velocity_x','head_ang_velocity_y','head_ang_velocity_z','head_ang_acc_x','head_ang_acc_y','head_ang_acc_z','left_hand_position_x','left_hand_position_y','left_hand_position_z','left_hand_velocity_x','left_hand_velocity_y','left_hand_velocity_z','left_hand_acc_x','left_hand_acc_y','left_hand_acc_z','left_hand_orientation_x','left_hand_orientation_y','left_hand_orientation_z','left_hand_orientation_w','left_hand_ang_velocity_x','left_hand_ang_velocity_y','left_hand_ang_velocity_z','left_hand_ang_acc_x','left_hand_ang_acc_y','left_hand_ang_acc_z','right_hand_position_x','right_hand_position_y','right_hand_position_z','right_hand_velocity_x','right_hand_velocity_y','right_hand_velocity_z','right_hand_acc_x','right_hand_acc_y','right_hand_acc_z','right_hand_orientation_x','right_hand_orientation_y','right_hand_orientation_z','right_hand_orientation_w','right_hand_ang_velocity_x','right_hand_ang_velocity_y','right_hand_ang_velocity_z','right_hand_ang_acc_x','right_hand_ang_acc_y','right_hand_ang_acc_z'])\n",
    "        X0=X0[features]\n",
    "        data_points=X0.shape[0]//window\n",
    "        #print(data_points)\n",
    "        X0=X0.head(data_points*window)\n",
    "        X0=np.array(X0)\n",
    "        X0=np.reshape(X0,((data_points,window,n_features)))\n",
    "        #print(X0.shape)\n",
    "        X=np.concatenate((X,X0))\n",
    "        Y0=np.zeros((data_points,2))\n",
    "        Y0[:,values[j]]=1\n",
    "        Y=np.concatenate((Y,Y0))\n",
    "        j+=1\n",
    "    # print(X[0])\n",
    "    #X_min = X.min(axis=1, keepdims=True)\n",
    "    #X_max = X.max(axis=1, keepdims=True)\n",
    "    #X=(X - X_min)/(X_max - X_min)\n",
    "    #print(X[0])\n",
    "    #print(X[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33)\n",
    "    print(X_train.shape)\n",
    "    \n",
    "    #print(y_train.head(100))\n",
    "    #print(Config(X_train, X_test))\n",
    "    config = Config(X_train, X_test)\n",
    "    print(\"Some useful info to get an insight on dataset's shape and normalisation:\")\n",
    "    print(\"features shape, labels shape, each features mean, each features standard deviation\")\n",
    "    print(X_test.shape, y_test.shape,\n",
    "          np.mean(X_test), np.std(X_test))\n",
    "    print(\"the dataset is therefore properly normalised, as expected.\")\n",
    "    print(config.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    X = tf.placeholder(tf.float32, [None, config.n_steps, config.n_inputs])\n",
    "    Y = tf.placeholder(tf.float32, [None, config.n_classes])\n",
    "\n",
    "    pred_Y = LSTM_Network(X, config)\n",
    "\n",
    "    # Loss,optimizer,evaluation\n",
    "    l2 = config.lambda_loss_amount * \\\n",
    "        sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\n",
    "    # Softmax loss and L2\n",
    "    cost = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=pred_Y)) + l2\n",
    "    optimizer = tf.train.AdamOptimizer(\n",
    "        learning_rate=config.learning_rate).minimize(cost)\n",
    "\n",
    "    correct_pred = tf.equal(tf.argmax(pred_Y, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traing iter: 0, test accuracy : 0.4433229863643646, loss : 0.8223296403884888\n",
      "traing iter: 1, test accuracy : 0.5077639818191528, loss : 0.753078281879425\n",
      "traing iter: 2, test accuracy : 0.5015528202056885, loss : 0.7263519763946533\n",
      "traing iter: 3, test accuracy : 0.5295031070709229, loss : 0.7091094255447388\n",
      "traing iter: 4, test accuracy : 0.5318322777748108, loss : 0.7012753486633301\n",
      "traing iter: 5, test accuracy : 0.5395962595939636, loss : 0.6963726878166199\n",
      "traing iter: 6, test accuracy : 0.5582298040390015, loss : 0.6931930184364319\n",
      "traing iter: 7, test accuracy : 0.5753105878829956, loss : 0.6908589601516724\n",
      "traing iter: 8, test accuracy : 0.5838509202003479, loss : 0.6890290975570679\n",
      "traing iter: 9, test accuracy : 0.5908384919166565, loss : 0.6874772906303406\n",
      "traing iter: 10, test accuracy : 0.5931677222251892, loss : 0.6860877275466919\n",
      "traing iter: 11, test accuracy : 0.590062141418457, loss : 0.684810996055603\n",
      "traing iter: 12, test accuracy : 0.5877329111099243, loss : 0.6836302280426025\n",
      "traing iter: 13, test accuracy : 0.5861801505088806, loss : 0.6825312376022339\n",
      "traing iter: 14, test accuracy : 0.5892857313156128, loss : 0.6814969182014465\n",
      "traing iter: 15, test accuracy : 0.5877329111099243, loss : 0.680509090423584\n",
      "traing iter: 16, test accuracy : 0.590062141418457, loss : 0.6795497536659241\n",
      "traing iter: 17, test accuracy : 0.5908384919166565, loss : 0.678600013256073\n",
      "traing iter: 18, test accuracy : 0.5931677222251892, loss : 0.6776396632194519\n",
      "traing iter: 19, test accuracy : 0.5939440727233887, loss : 0.6766533851623535\n",
      "traing iter: 20, test accuracy : 0.592391312122345, loss : 0.6756461262702942\n",
      "traing iter: 21, test accuracy : 0.5916149020195007, loss : 0.6746411919593811\n",
      "traing iter: 22, test accuracy : 0.592391312122345, loss : 0.6736578941345215\n",
      "traing iter: 23, test accuracy : 0.5986024737358093, loss : 0.6727001070976257\n",
      "traing iter: 24, test accuracy : 0.60326087474823, loss : 0.6717528104782104\n",
      "traing iter: 25, test accuracy : 0.60326087474823, loss : 0.6707811951637268\n",
      "traing iter: 26, test accuracy : 0.6055900454521179, loss : 0.6697595119476318\n",
      "traing iter: 27, test accuracy : 0.6102484464645386, loss : 0.6687203645706177\n",
      "traing iter: 28, test accuracy : 0.6102484464645386, loss : 0.6677192449569702\n",
      "traing iter: 29, test accuracy : 0.6133540272712708, loss : 0.6667835116386414\n",
      "traing iter: 30, test accuracy : 0.6156832575798035, loss : 0.6659345626831055\n",
      "traing iter: 31, test accuracy : 0.6125776171684265, loss : 0.6652042269706726\n",
      "traing iter: 32, test accuracy : 0.6156832575798035, loss : 0.6646345257759094\n",
      "traing iter: 33, test accuracy : 0.6172360181808472, loss : 0.6642626523971558\n",
      "traing iter: 34, test accuracy : 0.614130437374115, loss : 0.6640770435333252\n",
      "traing iter: 35, test accuracy : 0.6156832575798035, loss : 0.6639896035194397\n",
      "traing iter: 36, test accuracy : 0.614130437374115, loss : 0.663921594619751\n",
      "traing iter: 37, test accuracy : 0.6164596080780029, loss : 0.6638973951339722\n",
      "traing iter: 38, test accuracy : 0.6156832575798035, loss : 0.6639502644538879\n",
      "traing iter: 39, test accuracy : 0.6156832575798035, loss : 0.6640074253082275\n",
      "traing iter: 40, test accuracy : 0.6172360181808472, loss : 0.6638745665550232\n",
      "traing iter: 41, test accuracy : 0.6172360181808472, loss : 0.6633796691894531\n",
      "traing iter: 42, test accuracy : 0.6172360181808472, loss : 0.6625716090202332\n",
      "traing iter: 43, test accuracy : 0.6195651888847351, loss : 0.6616484522819519\n",
      "traing iter: 44, test accuracy : 0.6211180090904236, loss : 0.6607295274734497\n",
      "traing iter: 45, test accuracy : 0.6226708292961121, loss : 0.6598317623138428\n",
      "traing iter: 46, test accuracy : 0.6257764101028442, loss : 0.6589629650115967\n",
      "traing iter: 47, test accuracy : 0.6288819909095764, loss : 0.6581355929374695\n",
      "traing iter: 48, test accuracy : 0.6288819909095764, loss : 0.6573521494865417\n",
      "traing iter: 49, test accuracy : 0.6281055808067322, loss : 0.6566125750541687\n",
      "traing iter: 50, test accuracy : 0.6257764101028442, loss : 0.6559170484542847\n",
      "traing iter: 51, test accuracy : 0.6288819909095764, loss : 0.6552638411521912\n",
      "traing iter: 52, test accuracy : 0.6304348111152649, loss : 0.6546496152877808\n",
      "traing iter: 53, test accuracy : 0.6304348111152649, loss : 0.6540713906288147\n",
      "traing iter: 54, test accuracy : 0.6265528202056885, loss : 0.6535260677337646\n",
      "traing iter: 55, test accuracy : 0.6273291707038879, loss : 0.6530098915100098\n",
      "traing iter: 56, test accuracy : 0.6265528202056885, loss : 0.6525192260742188\n",
      "traing iter: 57, test accuracy : 0.6281055808067322, loss : 0.6520510315895081\n",
      "traing iter: 58, test accuracy : 0.6312111616134644, loss : 0.6516019701957703\n",
      "traing iter: 59, test accuracy : 0.6304348111152649, loss : 0.6511690616607666\n",
      "traing iter: 60, test accuracy : 0.6304348111152649, loss : 0.6507500410079956\n",
      "traing iter: 61, test accuracy : 0.6327639818191528, loss : 0.650343120098114\n",
      "traing iter: 62, test accuracy : 0.6319875717163086, loss : 0.6499466300010681\n",
      "traing iter: 63, test accuracy : 0.6312111616134644, loss : 0.6495594382286072\n",
      "traing iter: 64, test accuracy : 0.6296584010124207, loss : 0.6491808891296387\n",
      "traing iter: 65, test accuracy : 0.6319875717163086, loss : 0.6488101482391357\n",
      "traing iter: 66, test accuracy : 0.6327639818191528, loss : 0.6484473943710327\n",
      "traing iter: 67, test accuracy : 0.6327639818191528, loss : 0.6480921506881714\n",
      "traing iter: 68, test accuracy : 0.6312111616134644, loss : 0.6477439403533936\n",
      "traing iter: 69, test accuracy : 0.6281055808067322, loss : 0.647402286529541\n",
      "traing iter: 70, test accuracy : 0.6296584010124207, loss : 0.6470663547515869\n",
      "traing iter: 71, test accuracy : 0.6304348111152649, loss : 0.6467351317405701\n",
      "traing iter: 72, test accuracy : 0.6304348111152649, loss : 0.6464083790779114\n",
      "traing iter: 73, test accuracy : 0.6304348111152649, loss : 0.6460858583450317\n",
      "traing iter: 74, test accuracy : 0.6327639818191528, loss : 0.6457667946815491\n",
      "traing iter: 75, test accuracy : 0.6319875717163086, loss : 0.6454521417617798\n",
      "traing iter: 76, test accuracy : 0.6319875717163086, loss : 0.6451411843299866\n",
      "traing iter: 77, test accuracy : 0.6327639818191528, loss : 0.644834041595459\n",
      "traing iter: 78, test accuracy : 0.6335403919219971, loss : 0.6445308923721313\n",
      "traing iter: 79, test accuracy : 0.6335403919219971, loss : 0.6442310810089111\n",
      "traing iter: 80, test accuracy : 0.6327639818191528, loss : 0.643934965133667\n",
      "traing iter: 81, test accuracy : 0.6335403919219971, loss : 0.6436421871185303\n",
      "traing iter: 82, test accuracy : 0.6343167424201965, loss : 0.6433529853820801\n",
      "traing iter: 83, test accuracy : 0.635869562625885, loss : 0.6430670022964478\n",
      "traing iter: 84, test accuracy : 0.6374223828315735, loss : 0.6427847743034363\n",
      "traing iter: 85, test accuracy : 0.6374223828315735, loss : 0.6425062417984009\n",
      "traing iter: 86, test accuracy : 0.635869562625885, loss : 0.6422321796417236\n",
      "traing iter: 87, test accuracy : 0.635869562625885, loss : 0.6419631838798523\n",
      "traing iter: 88, test accuracy : 0.635869562625885, loss : 0.6416997313499451\n",
      "traing iter: 89, test accuracy : 0.6374223828315735, loss : 0.6414427161216736\n",
      "traing iter: 90, test accuracy : 0.6366459727287292, loss : 0.6411926746368408\n",
      "traing iter: 91, test accuracy : 0.635869562625885, loss : 0.6409503221511841\n",
      "traing iter: 92, test accuracy : 0.6366459727287292, loss : 0.640717089176178\n",
      "traing iter: 93, test accuracy : 0.638198733329773, loss : 0.6404929161071777\n",
      "traing iter: 94, test accuracy : 0.6397515535354614, loss : 0.6402784585952759\n",
      "traing iter: 95, test accuracy : 0.6413043737411499, loss : 0.6400747299194336\n",
      "traing iter: 96, test accuracy : 0.6436335444450378, loss : 0.6398819088935852\n",
      "traing iter: 97, test accuracy : 0.6428571343421936, loss : 0.639700710773468\n",
      "traing iter: 98, test accuracy : 0.6436335444450378, loss : 0.6395315527915955\n",
      "traing iter: 99, test accuracy : 0.6428571343421936, loss : 0.6393747329711914\n",
      "traing iter: 100, test accuracy : 0.6420807242393494, loss : 0.6392304301261902\n",
      "traing iter: 101, test accuracy : 0.6420807242393494, loss : 0.639099657535553\n",
      "traing iter: 102, test accuracy : 0.6420807242393494, loss : 0.6389821171760559\n",
      "traing iter: 103, test accuracy : 0.6428571343421936, loss : 0.638878345489502\n",
      "traing iter: 104, test accuracy : 0.6436335444450378, loss : 0.6387884616851807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traing iter: 105, test accuracy : 0.6420807242393494, loss : 0.6387128829956055\n",
      "traing iter: 106, test accuracy : 0.6444099545478821, loss : 0.6386514902114868\n",
      "traing iter: 107, test accuracy : 0.6451863646507263, loss : 0.638603687286377\n",
      "traing iter: 108, test accuracy : 0.6451863646507263, loss : 0.6385706663131714\n",
      "traing iter: 109, test accuracy : 0.6459627151489258, loss : 0.6385514736175537\n",
      "traing iter: 110, test accuracy : 0.6459627151489258, loss : 0.6385458111763\n",
      "traing iter: 111, test accuracy : 0.6451863646507263, loss : 0.6385535597801208\n",
      "traing iter: 112, test accuracy : 0.6482919454574585, loss : 0.6385743021965027\n",
      "traing iter: 113, test accuracy : 0.6498447060585022, loss : 0.6386072635650635\n",
      "traing iter: 114, test accuracy : 0.6506211161613464, loss : 0.6386510729789734\n",
      "traing iter: 115, test accuracy : 0.6498447060585022, loss : 0.6387055516242981\n",
      "traing iter: 116, test accuracy : 0.6498447060585022, loss : 0.6387689113616943\n",
      "traing iter: 117, test accuracy : 0.649068295955658, loss : 0.6388404965400696\n",
      "traing iter: 118, test accuracy : 0.6482919454574585, loss : 0.6389196515083313\n",
      "traing iter: 119, test accuracy : 0.6498447060585022, loss : 0.6390047073364258\n",
      "traing iter: 120, test accuracy : 0.6498447060585022, loss : 0.6390954852104187\n",
      "traing iter: 121, test accuracy : 0.6513975262641907, loss : 0.6391915678977966\n",
      "traing iter: 122, test accuracy : 0.6506211161613464, loss : 0.6392917633056641\n",
      "traing iter: 123, test accuracy : 0.6506211161613464, loss : 0.6393959522247314\n",
      "traing iter: 124, test accuracy : 0.6506211161613464, loss : 0.639504075050354\n",
      "traing iter: 125, test accuracy : 0.6506211161613464, loss : 0.6396158337593079\n",
      "traing iter: 126, test accuracy : 0.649068295955658, loss : 0.63973069190979\n",
      "traing iter: 127, test accuracy : 0.6482919454574585, loss : 0.6398485898971558\n",
      "traing iter: 128, test accuracy : 0.6475155353546143, loss : 0.6399697661399841\n",
      "traing iter: 129, test accuracy : 0.6459627151489258, loss : 0.6400938034057617\n",
      "traing iter: 130, test accuracy : 0.6444099545478821, loss : 0.6402209401130676\n",
      "traing iter: 131, test accuracy : 0.6444099545478821, loss : 0.6403513550758362\n",
      "traing iter: 132, test accuracy : 0.6459627151489258, loss : 0.6404843330383301\n",
      "traing iter: 133, test accuracy : 0.6459627151489258, loss : 0.6406199336051941\n",
      "traing iter: 134, test accuracy : 0.6451863646507263, loss : 0.6407593488693237\n",
      "traing iter: 135, test accuracy : 0.64673912525177, loss : 0.6409004926681519\n",
      "traing iter: 136, test accuracy : 0.64673912525177, loss : 0.6410450339317322\n",
      "traing iter: 137, test accuracy : 0.6475155353546143, loss : 0.6411920785903931\n",
      "traing iter: 138, test accuracy : 0.6475155353546143, loss : 0.6413418650627136\n",
      "traing iter: 139, test accuracy : 0.6475155353546143, loss : 0.6414936184883118\n",
      "traing iter: 140, test accuracy : 0.6475155353546143, loss : 0.641647458076477\n",
      "traing iter: 141, test accuracy : 0.6475155353546143, loss : 0.6418037414550781\n",
      "traing iter: 142, test accuracy : 0.649068295955658, loss : 0.6419618725776672\n",
      "traing iter: 143, test accuracy : 0.649068295955658, loss : 0.6421223282814026\n",
      "traing iter: 144, test accuracy : 0.6498447060585022, loss : 0.6422843933105469\n",
      "traing iter: 145, test accuracy : 0.649068295955658, loss : 0.6424487233161926\n",
      "traing iter: 146, test accuracy : 0.6498447060585022, loss : 0.6426147222518921\n",
      "traing iter: 147, test accuracy : 0.649068295955658, loss : 0.6427832245826721\n",
      "traing iter: 148, test accuracy : 0.6498447060585022, loss : 0.6429538726806641\n",
      "traing iter: 149, test accuracy : 0.6482919454574585, loss : 0.6431260704994202\n",
      "traing iter: 150, test accuracy : 0.6475155353546143, loss : 0.6433008909225464\n",
      "traing iter: 151, test accuracy : 0.6475155353546143, loss : 0.6434776186943054\n",
      "traing iter: 152, test accuracy : 0.6482919454574585, loss : 0.6436559557914734\n",
      "traing iter: 153, test accuracy : 0.6498447060585022, loss : 0.6438365578651428\n",
      "traing iter: 154, test accuracy : 0.6506211161613464, loss : 0.6440190672874451\n",
      "traing iter: 155, test accuracy : 0.6498447060585022, loss : 0.6442041397094727\n",
      "traing iter: 156, test accuracy : 0.6498447060585022, loss : 0.6443904638290405\n",
      "traing iter: 157, test accuracy : 0.6498447060585022, loss : 0.6445790529251099\n",
      "traing iter: 158, test accuracy : 0.6498447060585022, loss : 0.6447691917419434\n",
      "traing iter: 159, test accuracy : 0.649068295955658, loss : 0.6449610590934753\n",
      "traing iter: 160, test accuracy : 0.6482919454574585, loss : 0.6451547145843506\n",
      "traing iter: 161, test accuracy : 0.649068295955658, loss : 0.6453495025634766\n",
      "traing iter: 162, test accuracy : 0.649068295955658, loss : 0.6455462574958801\n",
      "traing iter: 163, test accuracy : 0.649068295955658, loss : 0.6457440257072449\n",
      "traing iter: 164, test accuracy : 0.6459627151489258, loss : 0.6459428071975708\n",
      "traing iter: 165, test accuracy : 0.6475155353546143, loss : 0.6461426019668579\n",
      "traing iter: 166, test accuracy : 0.6482919454574585, loss : 0.6463438272476196\n",
      "traing iter: 167, test accuracy : 0.6482919454574585, loss : 0.6465457677841187\n",
      "traing iter: 168, test accuracy : 0.6475155353546143, loss : 0.6467486619949341\n",
      "traing iter: 169, test accuracy : 0.6475155353546143, loss : 0.6469518542289734\n",
      "traing iter: 170, test accuracy : 0.6451863646507263, loss : 0.6471556425094604\n",
      "traing iter: 171, test accuracy : 0.6451863646507263, loss : 0.6473600268363953\n",
      "traing iter: 172, test accuracy : 0.6451863646507263, loss : 0.6475653052330017\n",
      "traing iter: 173, test accuracy : 0.6444099545478821, loss : 0.647770345211029\n",
      "traing iter: 174, test accuracy : 0.6451863646507263, loss : 0.647975742816925\n",
      "traing iter: 175, test accuracy : 0.6451863646507263, loss : 0.6481820344924927\n",
      "traing iter: 176, test accuracy : 0.6459627151489258, loss : 0.6483882069587708\n",
      "traing iter: 177, test accuracy : 0.6451863646507263, loss : 0.6485943794250488\n",
      "traing iter: 178, test accuracy : 0.6451863646507263, loss : 0.6488006114959717\n",
      "traing iter: 179, test accuracy : 0.6451863646507263, loss : 0.6490072011947632\n",
      "traing iter: 180, test accuracy : 0.6444099545478821, loss : 0.6492143273353577\n",
      "traing iter: 181, test accuracy : 0.6444099545478821, loss : 0.6494210362434387\n",
      "traing iter: 182, test accuracy : 0.6459627151489258, loss : 0.6496279239654541\n",
      "traing iter: 183, test accuracy : 0.6459627151489258, loss : 0.6498349905014038\n",
      "traing iter: 184, test accuracy : 0.64673912525177, loss : 0.650042712688446\n",
      "traing iter: 185, test accuracy : 0.64673912525177, loss : 0.6502506136894226\n",
      "traing iter: 186, test accuracy : 0.6459627151489258, loss : 0.6504591107368469\n",
      "traing iter: 187, test accuracy : 0.64673912525177, loss : 0.6506680846214294\n",
      "traing iter: 188, test accuracy : 0.6475155353546143, loss : 0.6508777141571045\n",
      "traing iter: 189, test accuracy : 0.6459627151489258, loss : 0.6510881185531616\n",
      "traing iter: 190, test accuracy : 0.6459627151489258, loss : 0.6512992978096008\n",
      "traing iter: 191, test accuracy : 0.6475155353546143, loss : 0.6515111923217773\n",
      "traing iter: 192, test accuracy : 0.6475155353546143, loss : 0.6517240405082703\n",
      "traing iter: 193, test accuracy : 0.64673912525177, loss : 0.6519379615783691\n",
      "traing iter: 194, test accuracy : 0.64673912525177, loss : 0.6521530747413635\n",
      "traing iter: 195, test accuracy : 0.6459627151489258, loss : 0.6523699164390564\n",
      "traing iter: 196, test accuracy : 0.6475155353546143, loss : 0.6525882482528687\n",
      "traing iter: 197, test accuracy : 0.6475155353546143, loss : 0.6528080105781555\n",
      "traing iter: 198, test accuracy : 0.6475155353546143, loss : 0.6530293226242065\n",
      "traing iter: 199, test accuracy : 0.6475155353546143, loss : 0.6532520651817322\n",
      "traing iter: 200, test accuracy : 0.6475155353546143, loss : 0.6534771919250488\n",
      "traing iter: 201, test accuracy : 0.6475155353546143, loss : 0.6537041068077087\n",
      "traing iter: 202, test accuracy : 0.6475155353546143, loss : 0.6539327502250671\n",
      "traing iter: 203, test accuracy : 0.6475155353546143, loss : 0.6541633605957031\n",
      "traing iter: 204, test accuracy : 0.64673912525177, loss : 0.6543964743614197\n",
      "traing iter: 205, test accuracy : 0.6475155353546143, loss : 0.6546313762664795\n",
      "traing iter: 206, test accuracy : 0.649068295955658, loss : 0.6548681855201721\n",
      "traing iter: 207, test accuracy : 0.6498447060585022, loss : 0.6551074385643005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traing iter: 208, test accuracy : 0.6498447060585022, loss : 0.6553493738174438\n",
      "traing iter: 209, test accuracy : 0.6498447060585022, loss : 0.6555939316749573\n",
      "traing iter: 210, test accuracy : 0.6498447060585022, loss : 0.6558412909507751\n",
      "traing iter: 211, test accuracy : 0.6506211161613464, loss : 0.6560911536216736\n",
      "traing iter: 212, test accuracy : 0.6506211161613464, loss : 0.6563428640365601\n",
      "traing iter: 213, test accuracy : 0.6506211161613464, loss : 0.6565978527069092\n",
      "traing iter: 214, test accuracy : 0.6529502868652344, loss : 0.6568556427955627\n",
      "traing iter: 215, test accuracy : 0.6513975262641907, loss : 0.6571162939071655\n",
      "traing iter: 216, test accuracy : 0.6506211161613464, loss : 0.6573798060417175\n",
      "traing iter: 217, test accuracy : 0.649068295955658, loss : 0.6576457023620605\n",
      "traing iter: 218, test accuracy : 0.6498447060585022, loss : 0.6579147577285767\n",
      "traing iter: 219, test accuracy : 0.6506211161613464, loss : 0.6581866145133972\n",
      "traing iter: 220, test accuracy : 0.6506211161613464, loss : 0.6584619283676147\n",
      "traing iter: 221, test accuracy : 0.6506211161613464, loss : 0.6587402820587158\n",
      "traing iter: 222, test accuracy : 0.6506211161613464, loss : 0.65902179479599\n",
      "traing iter: 223, test accuracy : 0.6513975262641907, loss : 0.6593072414398193\n",
      "traing iter: 224, test accuracy : 0.6506211161613464, loss : 0.6595958471298218\n",
      "traing iter: 225, test accuracy : 0.6506211161613464, loss : 0.6598883271217346\n",
      "traing iter: 226, test accuracy : 0.6506211161613464, loss : 0.660184383392334\n",
      "traing iter: 227, test accuracy : 0.6513975262641907, loss : 0.660484790802002\n",
      "traing iter: 228, test accuracy : 0.6506211161613464, loss : 0.6607890725135803\n",
      "traing iter: 229, test accuracy : 0.6498447060585022, loss : 0.6610980033874512\n",
      "traing iter: 230, test accuracy : 0.6482919454574585, loss : 0.6614108085632324\n",
      "traing iter: 231, test accuracy : 0.649068295955658, loss : 0.6617282032966614\n",
      "traing iter: 232, test accuracy : 0.6498447060585022, loss : 0.6620511412620544\n",
      "traing iter: 233, test accuracy : 0.6498447060585022, loss : 0.6623786091804504\n",
      "traing iter: 234, test accuracy : 0.6498447060585022, loss : 0.6627116799354553\n",
      "traing iter: 235, test accuracy : 0.649068295955658, loss : 0.663051426410675\n",
      "traing iter: 236, test accuracy : 0.649068295955658, loss : 0.6633970141410828\n",
      "traing iter: 237, test accuracy : 0.6498447060585022, loss : 0.6637499928474426\n",
      "traing iter: 238, test accuracy : 0.6498447060585022, loss : 0.6641115546226501\n",
      "traing iter: 239, test accuracy : 0.649068295955658, loss : 0.6644828915596008\n",
      "traing iter: 240, test accuracy : 0.649068295955658, loss : 0.6648651361465454\n",
      "traing iter: 241, test accuracy : 0.649068295955658, loss : 0.6652607917785645\n",
      "traing iter: 242, test accuracy : 0.6482919454574585, loss : 0.6656716465950012\n",
      "traing iter: 243, test accuracy : 0.6482919454574585, loss : 0.6660991907119751\n",
      "traing iter: 244, test accuracy : 0.6482919454574585, loss : 0.666545033454895\n",
      "traing iter: 245, test accuracy : 0.6482919454574585, loss : 0.6670055389404297\n",
      "traing iter: 246, test accuracy : 0.649068295955658, loss : 0.6674724221229553\n",
      "traing iter: 247, test accuracy : 0.6475155353546143, loss : 0.6679225564002991\n",
      "traing iter: 248, test accuracy : 0.64673912525177, loss : 0.6683199405670166\n",
      "traing iter: 249, test accuracy : 0.6459627151489258, loss : 0.6686288118362427\n",
      "traing iter: 250, test accuracy : 0.64673912525177, loss : 0.6688475012779236\n",
      "traing iter: 251, test accuracy : 0.64673912525177, loss : 0.6690160036087036\n",
      "traing iter: 252, test accuracy : 0.6436335444450378, loss : 0.6691751480102539\n",
      "traing iter: 253, test accuracy : 0.6451863646507263, loss : 0.6693446040153503\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-98cfc8180a6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m                           range(config.batch_size, config.train_count + 1, config.batch_size)):\n\u001b[0;32m     12\u001b[0m         sess.run(optimizer, feed_dict={X: X_train[start:end],\n\u001b[1;32m---> 13\u001b[1;33m                                        Y: y_train[start:end]})\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Test completely at every epoch: calculate accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\naru_piece\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\naru_piece\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\naru_piece\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\naru_piece\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\naru_piece\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=False))\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    y_pre=y_test[0]\n",
    "    best_accuracy = 0.0\n",
    "    # Start training for each batch and loop epochs\n",
    "    for i in range(config.training_epochs):\n",
    "        #print(config.learning_rate)\n",
    "        \n",
    "        for start, end in zip(range(0, config.train_count, config.batch_size),\n",
    "                              range(config.batch_size, config.train_count + 1, config.batch_size)):\n",
    "            sess.run(optimizer, feed_dict={X: X_train[start:end],\n",
    "                                           Y: y_train[start:end]})\n",
    "\n",
    "        # Test completely at every epoch: calculate accuracy\n",
    "        pred_out, accuracy_out, loss_out = sess.run(\n",
    "            [pred_Y, accuracy, cost],\n",
    "            feed_dict={\n",
    "                X: X_test,\n",
    "                Y: y_test\n",
    "            }\n",
    "        )\n",
    "        print(\"traing iter: {},\".format(i) +\n",
    "              \" test accuracy : {},\".format(accuracy_out) +\n",
    "              \" loss : {}\".format(loss_out))\n",
    "        if accuracy_out>best_accuracy:\n",
    "            y_pre=pred_out\n",
    "            best_accurcy=accuracy_out\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"final test accuracy: {}\".format(accuracy_out))\n",
    "    print(\"best epoch's test accuracy: {}\".format(best_accuracy))\n",
    "    print(\"\")   \n",
    "    best_accuracy = max(best_accuracy, accuracy_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.zeros_like(y_pre)\n",
    "b[np.arange(len(y_pre)), y_pre.argmax(1)] = 1\n",
    "y_pre=b\n",
    "#print(y_pre)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "for i in range(y_test.shape[1]):\n",
    "    print(\"Col {}\".format(i))\n",
    "    print(confusion_matrix(y_test[:,i], y_pre[:,i]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "predictions = y_pre\n",
    "%matplotlib inline\n",
    "print(\"Testing Accuracy: {}%\".format(100*accuracy))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Precision: {}%\".format(100*metrics.precision_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"Recall: {}%\".format(100*metrics.recall_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"f1_score: {}%\".format(100*metrics.f1_score(y_test, predictions, average=\"weighted\")))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix:\")\n",
    "confusion_matrix = metrics.confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))\n",
    "print(confusion_matrix)\n",
    "normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion matrix (normalised to % of total test data):\")\n",
    "print(normalised_confusion_matrix)\n",
    "print(\"Note: training and testing data is not equally distributed amongst classes, \")\n",
    "print(\"so it is normal that more than a 6th of the data is correctly classifier in the last category.\")\n",
    "\n",
    "# Plot Results: \n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.imshow(\n",
    "    normalised_confusion_matrix, \n",
    "    interpolation='nearest', \n",
    "    cmap=plt.cm.rainbow\n",
    ")\n",
    "plt.title(\"Confusion matrix \\n(normalised to % of total test data)\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(n_classes)\n",
    "plt.xticks(tick_marks, LABELS, rotation=90)\n",
    "plt.yticks(tick_marks, LABELS)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
